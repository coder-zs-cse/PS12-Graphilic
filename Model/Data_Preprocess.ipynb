{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "\n",
    "# Change directory to the folder where the .gz file is located\n",
    "os.chdir('/content/drive/MyDrive/Data/')\n",
    "\n",
    "# Specify the path to the .gz file\n",
    "gz_file_path = 'amazon-meta.txt.gz'\n",
    "\n",
    "# Extract the .gz file\n",
    "with gzip.open(gz_file_path, 'rb') as gz_file:\n",
    "    with open('amazon-meta.txt', 'wb') as out_file:\n",
    "        out_file.write(gz_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = '/content/drive/MyDrive/Data/'\n",
    "file_name = 'amazon-meta.txt'\n",
    "file_path = dataset_folder + file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from pandas import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_from_file(filename):\n",
    "    with open(filename, 'r',encoding='utf-8', errors='ignore') as f:\n",
    "        data = []\n",
    "        entry = {}\n",
    "        last_key = None\n",
    "        for num,line in enumerate(f):\n",
    "            if(num<3) :\n",
    "                continue\n",
    "            line = line.strip()\n",
    "            if line.startswith('Id:'):\n",
    "                if entry:\n",
    "                    if \"discontinued product\" not in entry[last_key]:\n",
    "                        data.append(entry)\n",
    "                entry = {\"Id\":line[3:].strip()}\n",
    "\n",
    "            elif line:\n",
    "                if not line[0].isalpha() or ':' not in line:\n",
    "                    entry[last_key] += ',' + line\n",
    "                else:\n",
    "                    key,value = line.split(':', 1)\n",
    "                    entry[key.strip()] = value.strip()\n",
    "                    last_key = key\n",
    "\n",
    "        if entry:\n",
    "            data.append(entry)\n",
    "    return data\n",
    "\n",
    "def post_Processing(filedata):\n",
    "    for item in filedata:\n",
    "\n",
    "        for key,value in item.items():\n",
    "            if key == 'similar':\n",
    "                count, *similar = value.split()\n",
    "                item[key] = {\"count\":count, \"ASIN ID\":similar}\n",
    "            elif key == 'categories':\n",
    "                subentry = {}\n",
    "                value = value.split(',')\n",
    "                subentry['count'] = value[0]\n",
    "                subentry['ASIN ID'] = value[1:]\n",
    "                item[key] = subentry\n",
    "            elif key == 'reviews':\n",
    "                pass\n",
    "                subentry = {}\n",
    "                value = value.split(',')\n",
    "\n",
    "                pattern = r'(\\S+):\\s*(\\S+)'\n",
    "                indexes = re.findall(pattern,value[0])\n",
    "                for index in indexes:\n",
    "                    subentry[index[0]] = index[1]\n",
    "\n",
    "                reviewList = []\n",
    "                for i in range(len(value[1:])):\n",
    "\n",
    "                    currentReview = {}\n",
    "                    currentReview[\"Review ID\"] = i+1\n",
    "                    currentReview[\"Date\"] = re.split(r'\\s+', value[1:][i])[0]\n",
    "                    pattern = r'(\\S+):\\s*(\\S+)'\n",
    "                    indexes = re.findall(pattern,value[1:][i])\n",
    "                    for index in indexes:\n",
    "                        currentReview[index[0]] = index[1]\n",
    "\n",
    "                    reviewList.append(currentReview)\n",
    "\n",
    "                subentry['review list'] = reviewList\n",
    "                item[key] = subentry\n",
    "\n",
    "    return filedata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = import_from_file(file_path)\n",
    "data = post_Processing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(dataset_folder+file_name[:-4]+'_filtered.json','w')\n",
    "json.dump(data,infile,indent=4)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
